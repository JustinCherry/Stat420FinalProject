schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#summary(full_model)
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
anova(significant_model, full_model)
anova(backwards_AIC, full_model)
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#summary(full_model)
significant_model = lm(WL ~ From + To + G + SRS + SOS + AP + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
anova(significant_model, full_model)
anova(backwards_AIC, full_model)
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#summary(full_model)
significant_model = lm(WL ~ From + To + G + SRS + SOS + AP + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
anova(significant_model, full_model)
anova(backwards_AIC, full_model)
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#summary(full_model)
significant_model = lm(WL ~ From + To + G + L + SRS + SOS + AP + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
anova(significant_model, full_model)
anova(backwards_AIC, full_model)
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#summary(full_model)
significant_model = lm(WL ~ From + To + G + SRS + SOS + AP + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
anova(significant_model, full_model)
anova(backwards_AIC, full_model)
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#summary(full_model)
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
anova(significant_model, full_model)
anova(backwards_AIC, full_model)
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#summary(full_model)
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
anova(significant_model, full_model)
#### THIS ONE IS GOOD, but it includes G and L... Which you can deduce Win/Loss ratio from it.
anova(backwards_AIC, full_model)
anova(significant_model, backwards_AIC)
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#summary(full_model)
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
anova(significant_model, full_model)
#### THIS ONE IS GOOD, but it includes G and L... Which you can deduce Win/Loss ratio from it.
anova(backwards_AIC, full_model)
anova(significant_model, backwards_AIC)
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
anova(significant_model, full_model)
#### THIS ONE IS GOOD, but it includes G and L... Which you can deduce Win/Loss ratio from it.
anova(backwards_AIC, full_model)
anova(significant_model, backwards_AIC)
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
n = length(full_model$residuals)
backward_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
backwards_BIC
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
n = length(full_model$residuals)
backward_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
backward_BIC
#anova(significant_model, full_model)
#### THIS ONE IS GOOD, but it includes G and L... Which you can deduce Win/Loss ratio from it.
#anova(backwards_AIC, full_model)
#anova(significant_model, backwards_AIC)
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
n = length(full_model$residuals)
backwards_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
backwards_BIC
#anova(significant_model, full_model)
#### THIS ONE IS GOOD, but it includes G and L... Which you can deduce Win/Loss ratio from it.
#anova(backwards_AIC, full_model)
#anova(significant_model, backwards_AIC)
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
n = length(full_model$residuals)
backwards_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backwards_BIC
start_model = lm(WL ~ 1, data = schoolData)
forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, direction = "forward")
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
n = length(full_model$residuals)
backwards_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backwards_BIC
start_model = lm(WL ~ 1, data = schoolData)
forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, direction = "forward")
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
n = length(full_model$residuals)
backwards_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backwards_BIC
start_model = lm(WL ~ 1, data = schoolData)
forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, direction = "forward")
library(readr)
schoolData = read_csv("SchoolData.csv")
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
n = length(full_model$residuals)
backwards_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backwards_BIC
na.omit(schoolData)
#start_model = lm(WL ~ 1, data = schoolData)
#forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, #direction = "forward")
#forwards_BIC
#anova(significant_model, full_model)
#### THIS ONE IS GOOD, but it includes G and L... Which you can deduce Win/Loss ratio from it.
#anova(backwards_AIC, full_model)
#anova(significant_model, backwards_AIC)
library(readr)
schoolData = read_csv("SchoolData.csv")
schoolData = na.omit(schoolData)
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
n = length(full_model$residuals)
backwards_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backwards_BIC
#start_model = lm(WL ~ 1, data = schoolData)
#forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, #direction = "forward")
#forwards_BIC
#anova(significant_model, full_model)
#### THIS ONE IS GOOD, but it includes G and L... Which you can deduce Win/Loss ratio from it.
#anova(backwards_AIC, full_model)
#anova(significant_model, backwards_AIC)
library(readr)
schoolData = read_csv("SchoolData.csv")
schoolData = na.omit(schoolData)
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backwards_AIC = step(full_model, direction = "backward", trace = 0)
#backwards_AIC
n = length(full_model$residuals)
backwards_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backwards_BIC
start_model = lm(WL ~ 1, data = schoolData)
forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, direction = "forward")
forwards_BIC
library(readr)
schoolData = read_csv("SchoolData.csv")
schoolData = na.omit(schoolData)
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backward_AIC = step(full_model, direction = "backward", trace = 0)
#backward_AIC
n = length(full_model$residuals)
backward_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backward_BIC
start_model = lm(WL ~ 1, data = schoolData)
forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, direction = "forward", trace = 0)
forward_BIC
#anova(significant_model, full_model)
#### THIS ONE IS GOOD, but it includes G and L... Which you can deduce Win/Loss ratio from it.
#anova(backward_AIC, full_model)
#anova(significant_model, backward_AIC)
library(readr)
schoolData = read_csv("SchoolData.csv")
schoolData = na.omit(schoolData)
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backward_AIC = step(full_model, direction = "backward", trace = 0)
#backward_AIC
n = length(full_model$residuals)
backward_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
backward_BIC
start_model = lm(WL ~ 1, data = schoolData)
forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, direction = "forward", trace = 0)
forward_BIC
#anova(significant_model, full_model)
#### THIS ONE IS GOOD, but it includes G and L... Which you can deduce Win/Loss ratio from it.
#anova(backward_AIC, full_model)
#anova(significant_model, backward_AIC)
anova(forward_BIC, backward_BIC)
library(readr)
schoolData = read_csv("SchoolData.csv")
schoolData = na.omit(schoolData)
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backward_AIC = step(full_model, direction = "backward", trace = 0)
#backward_AIC
n = length(full_model$residuals)
backward_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backward_BIC
start_model = lm(WL ~ 1, data = schoolData)
forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, direction = "forward", trace = 0)
#forward_BIC
#anova(significant_model, full_model)
#### THIS ONE IS GOOD, but it includes G and L... Which you can deduce Win/Loss ratio from it.
#anova(backward_AIC, full_model)
#anova(significant_model, backward_AIC)
anova(backward_BIC, forward_BIC)
library(readr)
schoolData = read_csv("SchoolData.csv")
schoolData = na.omit(schoolData)
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backward_AIC = step(full_model, direction = "backward", trace = 0)
#backward_AIC
n = length(full_model$residuals)
backward_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backward_BIC
start_model = lm(WL ~ 1, data = schoolData)
forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, direction = "forward", trace = 0)
#forward_BIC
#anova(significant_model, full_model)
#### THIS ONE IS GOOD, but it includes G and L... Which you can deduce Win/Loss ratio from it.
#anova(backward_AIC, full_model)
#anova(significant_model, backward_AIC)
#anova(backward_BIC, forward_BIC)
anova(forward_BIC, full_model)
library(readr)
schoolData = read_csv("SchoolData.csv")
schoolData = na.omit(schoolData)
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backward_AIC = step(full_model, direction = "backward", trace = 0)
#backward_AIC
n = length(full_model$residuals)
backward_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backward_BIC
start_model = lm(WL ~ 1, data = schoolData)
forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, direction = "forward", trace = 0)
#forward_BIC
#anova(significant_model, full_model)
#### THIS ONE IS GOOD, but it includes G and L... Which you can deduce Win/Loss ratio from it.
#anova(backward_AIC, full_model)
#anova(significant_model, backward_AIC)
anova(backward_BIC, forward_BIC)
anova(forward_BIC, full_model)
library(readr)
schoolData = read_csv("SchoolData.csv")
schoolData = na.omit(schoolData)
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backward_AIC = step(full_model, direction = "backward", trace = 0)
#backward_AIC
n = length(full_model$residuals)
backward_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backward_BIC
start_model = lm(WL ~ 1, data = schoolData)
forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, direction = "forward", trace = 0)
#forward_BIC
#anova(significant_model, full_model)
#### THIS ONE IS GOOD, but it includes G and L... Which you can deduce Win/Loss ratio from it.
anova(backward_AIC, full_model)
#anova(significant_model, backward_AIC)
anova(backward_BIC, forward_BIC)
anova(forward_BIC, full_model)
library(readr)
schoolData = read_csv("SchoolData.csv")
schoolData = na.omit(schoolData)
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backward_AIC = step(full_model, direction = "backward", trace = 0)
#backward_AIC
n = length(full_model$residuals)
backward_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backward_BIC
start_model = lm(WL ~ 1, data = schoolData)
forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, direction = "forward", trace = 0)
#forward_BIC
#anova(significant_model, full_model)
#### THIS ONE IS GOOD, but it includes G and L... Which you can deduce Win/Loss ratio from it.
#anova(backward_AIC, full_model)
#anova(significant_model, backward_AIC)
#anova(backward_BIC, forward_BIC)
#anova(forward_BIC, full_model)
par(mfrow=c(1,2))
plot_fitted_resid(model_e)
cor(longley)
cor(longley)["GNP", "Year"]
model_2 = lm(Employed ~ . - Population, data = longley)
cor(resid(model), resid(model_2))
model_b = lm(Employed ~ ., data = longley)
names(which(summary(model_b)$coef[, "Pr(>|t|)"] < 0.05))
model_e = lm(Employed ~ Unemployed + Armed.Forces + Year, data = longley)
vif(model_e)
model_b = lm(Employed ~ ., data = longley)
model_e = lm(Employed ~ Unemployed + Armed.Forces + Year, data = longley)
anova(model_e, model_b)
library(lmtest)
plot_fitted_resid = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
plot(fitted(model), resid(model),
col = pointcol, pch = 20, cex = 1.5,
xlab = "Fitted", ylab = "Residuals")
abline(h = 0, col = linecol, lwd = 2)
}
plot_qq = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
qqnorm(resid(model), col = pointcol, pch = 20, cex = 1.5)
qqline(resid(model), col = linecol, lwd = 2)
}
par(mfrow=c(1,2))
plot_fitted_resid(model_e)
plot_qq(model_e)
bptest(model_e)
shapiro.test(model_e$residuals)
library(readr)
schoolData = read_csv("SchoolData.csv")
schoolData = na.omit(schoolData)
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backward_AIC = step(full_model, direction = "backward", trace = 0)
#backward_AIC
n = length(full_model$residuals)
backward_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backward_BIC
start_model = lm(WL ~ 1, data = schoolData)
forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, direction = "forward", trace = 0)
#forward_BIC
plot_fitted_resid = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
plot(fitted(model), resid(model),
col = pointcol, pch = 20, cex = 1.5,
xlab = "Fitted", ylab = "Residuals")
abline(h = 0, col = linecol, lwd = 2)
}
plot_qq = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
qqnorm(resid(model), col = pointcol, pch = 20, cex = 1.5)
qqline(resid(model), col = linecol, lwd = 2)
}
plot_fitted_resid = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
plot(fitted(model), resid(model),
col = pointcol, pch = 20, cex = 1.5,
xlab = "Fitted", ylab = "Residuals")
abline(h = 0, col = linecol, lwd = 2)
}
plot_qq = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
qqnorm(resid(model), col = pointcol, pch = 20, cex = 1.5)
qqline(resid(model), col = linecol, lwd = 2)
}
plot_fitted_resid(forward_BIC)
plot_qq(forward_BIC)
bptest(forward_BIC)
shapiro.test(forward_BIC$residuals)
plot_fitted_resid(forward_BIC)
plot_qq(forward_BIC)
### BP TEST WE WANT A LARGE P-VALUE (NO violation with the constant variance assumption)
bptest(forward_BIC)
### SHAPIRO TEST WE WANT A LARGE P-VALUE (NO violation with the normality assumption)
shapiro.test(forward_BIC$residuals)
library(readr)
schoolData = read_csv("SchoolData.csv")
schoolData = na.omit(schoolData)
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backward_AIC = step(full_model, direction = "backward", trace = 0)
#backward_AIC
n = length(full_model$residuals)
backward_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backward_BIC
##### MAYBE THIS IS THE MODEL WE WANT TO USE....
start_model = lm(WL ~ 1, data = schoolData)
forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, direction = "forward", trace = 0)
#forward_BIC
plot_fitted_resid = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
plot(fitted(model), resid(model),
col = pointcol, pch = 20, cex = 1.5,
xlab = "Fitted", ylab = "Residuals")
abline(h = 0, col = linecol, lwd = 2)
}
plot_qq = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
qqnorm(resid(model), col = pointcol, pch = 20, cex = 1.5)
qqline(resid(model), col = linecol, lwd = 2)
}
plot_fitted_resid(backward_BIC)
plot_qq(backward_BIC)
### BP TEST WE WANT A LARGE P-VALUE (NO violation with the constant variance assumption)
bptest(backward_BIC)
### SHAPIRO TEST WE WANT A LARGE P-VALUE (NO violation with the normality assumption)
shapiro.test(backward_BIC$residuals)
plot_fitted_resid(backward_BIC)
plot_qq(backward_BIC)
### BP TEST WE WANT A LARGE P-VALUE (NO violation with the constant variance assumption)
bptest(backward_BIC)
### SHAPIRO TEST WE WANT A LARGE P-VALUE (NO violation with the normality assumption)
shapiro.test(backward_BIC$residuals)
plot_fitted_resid(significant_model)
plot_qq(significant_model)
### BP TEST WE WANT A LARGE P-VALUE (NO violation with the constant variance assumption)
bptest(significant_model)
### SHAPIRO TEST WE WANT A LARGE P-VALUE (NO violation with the normality assumption)
shapiro.test(significant_model$residuals)
library(readr)
schoolData = read_csv("SchoolData.csv")
schoolData = na.omit(schoolData)
full_model = lm(WL ~ . - (School + City + State), data = schoolData)
#full_model
significant_model = lm(WL ~ From + To + SRS + SOS + CTRN + NCAA, data = schoolData)
#significant_model
backward_AIC = step(full_model, direction = "backward", trace = 0)
#backward_AIC
n = length(full_model$residuals)
backward_BIC = step(full_model, direction = "backward", k = log(n), trace = 0)
#backward_BIC
##### MAYBE THIS IS THE MODEL WE WANT TO USE....
start_model = lm(WL ~ 1, data = schoolData)
forward_BIC = step(start_model, scope = WL ~ From + To + Yrs + G + SRS + SOS + AP + CREG + CTRN + NCAA + FF + NC, direction = "forward", trace = 0)
#forward_BIC
crazy_model = lm(WL ~ W + L, data = schoolData)
plot_fitted_resid(crazy_model)
plot_qq(crazy_model)
### BP TEST WE WANT A LARGE P-VALUE (NO violation with the constant variance assumption)
bptest(crazy_model)
### SHAPIRO TEST WE WANT A LARGE P-VALUE (NO violation with the normality assumption)
shapiro.test(crazy_model$residuals)
